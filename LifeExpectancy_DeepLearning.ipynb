{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression \n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing  import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/kdpat/Downloads/life-expectancy-who/led.csv')\n",
    "\n",
    "##### Mean values for missing values group by Country\n",
    "data_grouped1=data.groupby(['Country'])\n",
    "data_imputed = data_grouped1.transform(lambda grp: grp.fillna(grp.mean()))\n",
    "\n",
    "#### Target Column: remove record without values\n",
    "data_imputed = data_imputed.dropna(axis=0, subset=['Lifeexpectancy'])\n",
    "data_imputed[['Country']]=data[['Country']]\n",
    "data_imputed[['Status']]=data[['Status']]\n",
    "\n",
    "\n",
    "##### Mean values for missing valuesgroup by status\n",
    "data_grouped2=data_imputed.groupby(['Status'])\n",
    "data_imputed = data_grouped2.transform(lambda grp: grp.fillna(grp.mean()))\n",
    "data_imputed[['Country']]=data[['Country']]\n",
    "data_imputed[['Status']]=data[['Status']]\n",
    "\n",
    "\n",
    "#### Binary Columns\n",
    "data_imputed['Status'] = data_imputed['Status'].map({'Developing':1, 'Developed':0}).astype(int)\n",
    "data_imputed.describe(include=['O'])\n",
    "\n",
    "#### Vector Column\n",
    "Country=pd.get_dummies(data_imputed['Country'],columns='Country',prefix='Country')\n",
    "Year=pd.get_dummies(data_imputed['Year'],columns='Year',prefix='Year')\n",
    "data_imputed=pd.concat([data_imputed, Country], axis=1)\n",
    "data_imputed=pd.concat([data_imputed, Year], axis=1)\n",
    "\n",
    "#### Drop original vector column\n",
    "data_imputed.drop(['Country'],axis=1,inplace= True)\n",
    "data_imputed.drop(['Year'],axis=1,inplace= True)\n",
    "\n",
    "#### x and Y\n",
    "x=data_imputed.copy()\n",
    "x.drop(['Lifeexpectancy'],axis=1,inplace= True)\n",
    "y=data_imputed['Lifeexpectancy']\n",
    "#y=pd.DataFrame(y)\n",
    "\n",
    "\n",
    "#split train-test data and scalling \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=0)\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train,y_train,random_state=0)\n",
    "mn = MinMaxScaler()\n",
    "x_train = pd.DataFrame(mn.fit_transform(x_train))\n",
    "x_test = pd.DataFrame(mn.transform(x_test))\n",
    "x_tr = pd.DataFrame(mn.fit_transform(x_tr))\n",
    "x_val = pd.DataFrame(mn.transform(x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Bagging \n",
    "### 1.1 Bagging with SVM Kernel=rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with SVM Kernel=rbf : Train score: 0.9897\n",
      "Bagging with SVM Kernel=rbf : Test score: 0.9536\n"
     ]
    }
   ],
   "source": [
    "lregSVRR = SVR(kernel='rbf', gamma=0.1, C=100)\n",
    "bag_lregSVRR_grid = BaggingRegressor(lregSVRR, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "param_grid_bag_lreg = {\"n_estimators\": [2, 5, 10],\n",
    "              \"max_samples\": [0.2, 0.5, 0.7, 1.0]\n",
    "              }\n",
    "bag_lregSVRR_grid = GridSearchCV(bag_lregSVRR_grid, param_grid_bag_lreg, cv = 5) \n",
    "bag_lregSVRR_grid.fit(x_train, y_train)\n",
    "\n",
    "print('Bagging with SVM Kernel=rbf : Train score: {:.4f}'.format(bag_lregSVRR_grid.score(x_train, y_train)))\n",
    "print('Bagging with SVM Kernel=rbf : Test score: {:.4f}'.format(bag_lregSVRR_grid.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Bagging with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with Linear Regression : Train score: 0.9654\n",
      "Bagging with Linear Regression : Test score: 0.9489\n"
     ]
    }
   ],
   "source": [
    "lreg = LinearRegression()\n",
    "bag_lreg_grid = BaggingRegressor(lreg, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "param_grid_bag_lreg = {\"n_estimators\": [2, 5, 10],\n",
    "              \"max_samples\": [0.2, 0.5, 0.7, 1.0]\n",
    "              }\n",
    "bag_lreg_grid = GridSearchCV(bag_lreg_grid, param_grid_bag_lreg, cv = 5) \n",
    "bag_lreg_grid.fit(x_train, y_train)\n",
    "\n",
    "print('Bagging with Linear Regression : Train score: {:.4f}'.format(bag_lreg_grid.score(x_train, y_train)))\n",
    "print('Bagging with Linear Regression : Test score: {:.4f}'.format(bag_lreg_grid.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pasting \n",
    "### 2.1 Pasting with SVM Kernel=rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting with SVM Kernel=rbf: 0.9958\n",
      "Pasting with SVM Kernel=rbf: 0.9578\n"
     ]
    }
   ],
   "source": [
    "lregSVRR = SVR(kernel='rbf', gamma=0.1, C=100)\n",
    "pas_lregSVRR = BaggingRegressor(lregSVRR, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "#pas_lregSVRR.fit(x_train, y_train)\n",
    "param_grid_pag_lregSVRR = {\"n_estimators\": [2, 5, 10],\n",
    "              \"max_samples\": [0.2, 0.5, 0.7, 1.0]\n",
    "              }\n",
    "pas_lregSVRR_grid = GridSearchCV(pas_lregSVRR, param_grid_pag_lregSVRR, cv = 5) \n",
    "pas_lregSVRR_grid.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print('Pasting with SVM Kernel=rbf: {:.4f}'.format(pas_lregSVRR_grid.score(x_train, y_train)))\n",
    "print('Pasting with SVM Kernel=rbf: {:.4f}'.format(pas_lregSVRR_grid.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pasting with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting with Linear Regression: Train score: 0.9958\n",
      "Pasting with Linear Regression: Test score: 0.9578\n"
     ]
    }
   ],
   "source": [
    "lreg = LinearRegression()\n",
    "pas_lreg = BaggingRegressor(lreg, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "param_grid_pag_lreg = {\"n_estimators\": [2, 5, 10],\n",
    "              \"max_samples\": [0.2, 0.5, 0.7, 1.0]\n",
    "              }\n",
    "pas_lreg_grid = GridSearchCV(pas_lregSVRR, param_grid_pag_lreg, cv = 5) \n",
    "pas_lreg_grid.fit(x_train, y_train)\n",
    "print('Pasting with Linear Regression: Train score: {:.4f}'.format(pas_lreg_grid.score(x_train, y_train)))\n",
    "print('Pasting with Linear Regression: Test score: {:.4f}'.format(pas_lreg_grid.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 AdaBoosting \n",
    "### 3.1 AdaBoosting with SVM Kernel=rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting with SVM Kernel=rbf : Train score: 0.9992\n",
      "AdaBoosting with SVM Kernel=rbf : Test score: 0.9539\n"
     ]
    }
   ],
   "source": [
    "lregSVRR = SVR(kernel='rbf', gamma=0.1, C=100)\n",
    "ada_lregSVRR = AdaBoostRegressor(lregSVRR, loss='square', learning_rate=0.5, random_state=0)\n",
    "ada_lregSVRR.fit(x_train, y_train)\n",
    "print('AdaBoosting with SVM Kernel=rbf : Train score: {:.4f}'.format(ada_lregSVRR.score(x_train, y_train)))\n",
    "print('AdaBoosting with SVM Kernel=rbf : Test score: {:.4f}'.format(ada_lregSVRR.score(x_test, y_test)))\n",
    "y_pred = ada_lregSVRR.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 AdaBoosting with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoosting with Linear Regression: Train score: 0.9394\n",
      "AdaBoosting with Linear Regression: Test score: 0.9132\n"
     ]
    }
   ],
   "source": [
    "lreg = LinearRegression()\n",
    "ada_lreg = AdaBoostRegressor(lreg, loss='square', learning_rate=0.5, random_state=0)\n",
    "ada_lreg.fit(x_train, y_train)\n",
    "print('AdaBoosting with Linear Regression: Train score: {:.4f}'.format(ada_lreg.score(x_train, y_train)))\n",
    "print('AdaBoosting with Linear Regression: Test score: {:.4f}'.format(ada_lreg.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting: Train score: 0.9413\n",
      "Gradient Boosting: Test score: 0.9139\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(random_state=0,learning_rate=0.5,n_estimators=10)\n",
    "gbrt.fit(x_train, y_train)\n",
    "\n",
    "print(\"Gradient Boosting: Train score: {:.4f}\".format(gbrt.score(x_train, y_train)))\n",
    "print(\"Gradient Boosting: Test score: {:.4f}\".format(gbrt.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Features 169\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(.95)\n",
    "x_train_pca =  pd.DataFrame(pca.fit_transform(x_train))\n",
    "x_test_pca = pd.DataFrame(pca.transform(x_test))\n",
    "x_tr_pca = pd.DataFrame(pca.fit_transform(x_tr))\n",
    "x_val_pca = pd.DataFrame(pca.transform(x_val))\n",
    "\n",
    "#print(x_train_pca.shape,x_test_pca.shape,x_tr_pca.shape,x_val_pca.shape)\n",
    "\n",
    "#print(\"Variation explained\",pca.explained_variance_ratio_)\n",
    "print(\"No. of Features in Reduced Data\",pca.n_components_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Cross Validation Score: 0.854794 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "cvsl={'Model':[],'Mean_Score':[],'Std':[]}\n",
    "Cross_validation_Score = pd.DataFrame(cvsl)\n",
    "lreg = LinearRegression()\n",
    "cslreg=cross_val_score(lreg,x_train_pca,y_train,cv=5)\n",
    "Cross_validation_Score = Cross_validation_Score.append({'Model':'Linear Regression','Mean_Score':cslreg.mean(),'Std':cslreg.std() * 2}, ignore_index=True)\n",
    "print(\"Avg Cross Validation Score: %0.6f (+/- %0.2f)\" % (cslreg.mean(), cslreg.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8566\n",
      "Best parameters: {'alpha': 1}\n",
      "Avg Cross Validation Score: 0.856707 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "x_range = [0.01, 0.1, 1, 10, 100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "best_score=0\n",
    "for alpha in x_range: \n",
    "    ridge = Ridge(alpha)\n",
    "    ridge.fit(x_tr_pca,y_tr)\n",
    "    train_score_list.append(ridge.score(x_tr_pca,y_tr))\n",
    "    score=ridge.score(x_val_pca, y_val)\n",
    "    test_score_list.append((score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameters = {'alpha': alpha}\n",
    "\n",
    "print(\"Best score: {:.4f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "\n",
    "ridge = Ridge(1)\n",
    "csridge=cross_val_score(ridge,x_train_pca,y_train,cv=5)\n",
    "Cross_validation_Score = Cross_validation_Score.append({'Model':'Ridge','Mean_Score':csridge.mean(),'Std':csridge.std() * 2}, ignore_index=True)\n",
    "print(\"Avg Cross Validation Score: %0.6f (+/- %0.2f)\" % (csridge.mean(), csridge.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8443\n",
      "Best parameters: {'alpha': 0.01}\n",
      "Avg Cross Validation score: 0.842413 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "x_range = [0.01, 0.1, 1, 10, 100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "best_score=0\n",
    "for alpha in x_range: \n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(x_tr_pca,y_tr)\n",
    "    train_score_list.append(lasso.score(x_tr_pca,y_tr))\n",
    "    score=lasso.score(x_val_pca, y_val)\n",
    "    test_score_list.append((score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameters = {'alpha': alpha}\n",
    "\n",
    "print(\"Best score: {:.4f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "\n",
    "\n",
    "lasso = Lasso(0.01)\n",
    "cslasso=cross_val_score(lasso,x_train_pca,y_train,cv=5)\n",
    "Cross_validation_Score = Cross_validation_Score.append({'Model':'Lasso','Mean_Score':cslasso.mean(),'Std':cslasso.std() * 2}, ignore_index=True)\n",
    "print(\"Avg Cross Validation score: %0.6f (+/- %0.2f)\" % (cslasso.mean(), cslasso.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Cross Validation score: 0.854794 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "lreg = LinearRegression()\n",
    "poly = PolynomialFeatures(1)\n",
    "X_train_poly = poly.fit_transform(x_train_pca)\n",
    "cslregpoly=cross_val_score(lreg,X_train_poly,y_train,cv=5)\n",
    "Cross_validation_Score = Cross_validation_Score.append({'Model':'Polynomial Regression','Mean_Score':cslregpoly.mean(),'Std':cslregpoly.std() * 2}, ignore_index=True)\n",
    "print(\"Avg Cross Validation score: %0.6f (+/- %0.2f)\" % (cslregpoly.mean(), cslregpoly.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8386\n",
      "Best parameters: {'C': 1}\n",
      "Avg Cross validation score: 0.836388 (+/- 0.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdpat\\AppData\\Local\\Continuum\\anaconda3\\envs\\gputest\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "x_range = [0.01, 0.1, 1, 10]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "best_score=0\n",
    "for c in x_range: \n",
    "    lregSVR = LinearSVR(C=c)\n",
    "    lregSVR.fit(x_tr_pca,y_tr)\n",
    "    train_score_list.append(lregSVR.score(x_tr_pca,y_tr))\n",
    "    score=lregSVR.score(x_val_pca, y_val)\n",
    "    test_score_list.append((score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameters = {'C': c}\n",
    "\n",
    "print(\"Best score: {:.4f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "\n",
    "\n",
    "lregSVR = LinearSVR(C=1)\n",
    "cslregSVR=cross_val_score(lregSVR,x_train_pca,y_train,cv=5)\n",
    "Cross_validation_Score = Cross_validation_Score.append({'Model':'SVM Simple','Mean_Score':cslregSVR.mean(),'Std':cslregSVR.std() * 2}, ignore_index=True)\n",
    "print(\"Avg Cross validation score: %0.6f (+/- %0.2f)\" % (cslregSVR.mean(), cslregSVR.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 SVM Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8395\n",
      "Best parameters: {'C': 1}\n",
      "Avg Cross validation score: 0.836355 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "x_range = [0.01, 0.1, 1, 10]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "best_score=0\n",
    "for c in x_range: \n",
    "    lregSVRL = SVR(kernel='linear', C=c)\n",
    "    lregSVRL.fit(x_tr_pca,y_tr)\n",
    "    train_score_list.append(lregSVRL.score(x_tr_pca,y_tr))\n",
    "    score=lregSVRL.score(x_val_pca, y_val)\n",
    "    test_score_list.append((score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameters = {'C': c}\n",
    "\n",
    "print(\"Best score: {:.4f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "\n",
    "lregSVRL = SVR(kernel='linear', C=1)\n",
    "cslregSVRL=cross_val_score(lregSVRL,x_train_pca,y_train,cv=5)\n",
    "Cross_validation_Score = Cross_validation_Score.append({'Model':'SVM Kernel=Linear','Mean_Score':cslregSVRL.mean(),'Std':cslregSVRL.std() * 2}, ignore_index=True)\n",
    "print(\"Avg Cross validation score: %0.6f (+/- %0.2f)\" % (cslregSVRL.mean(), cslregSVRL.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 SVM Kernel=rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9253\n",
      "Best parameters: {'gamma': 0.1, 'C': 100}\n",
      "Avg Cross validation score: 0.936589 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "Gamma = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "best_score=0\n",
    "for gamma in Gamma: \n",
    "    for c in C:\n",
    "        lregSVRR = SVR(kernel='rbf', gamma=gamma, C=c)\n",
    "        lregSVRR.fit(x_tr_pca,y_tr)\n",
    "        train_score_list.append(lregSVRR.score(x_tr_pca,y_tr))\n",
    "        score=lregSVRR.score(x_val_pca, y_val)\n",
    "        test_score_list.append((score))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'gamma': gamma, 'C': c}\n",
    "\n",
    "print(\"Best score: {:.4f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "\n",
    "\n",
    "lregSVRR = SVR(kernel='rbf', gamma=0.1, C=100)\n",
    "cslregSVRR=cross_val_score(lregSVRR,x_train_pca,y_train,cv=5)\n",
    "Cross_validation_Score = Cross_validation_Score.append({'Model':'SVM Kernel=rbf','Mean_Score':cslregSVRR.mean(),'Std':cslregSVRR.std() * 2}, ignore_index=True)\n",
    "print(\"Avg Cross validation score: %0.6f (+/- %0.2f)\" % (cslregSVRR.mean(), cslregSVRR.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 SVM Kernel=poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.1739\n",
      "Best parameters: {'Degree': 2, 'C': 1000}\n",
      "Avg Cross validation score: 0.183494 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "Degree = [2,3,4]\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "best_score=0\n",
    "for degree in Degree: \n",
    "    for c in C:\n",
    "        lregSVRP = SVR(kernel='poly', degree=degree, C=c, gamma='auto')\n",
    "        lregSVRP.fit(x_tr_pca,y_tr)\n",
    "        train_score_list.append(lregSVRP.score(x_tr_pca,y_tr))\n",
    "        score=lregSVRP.score(x_val_pca, y_val)\n",
    "        test_score_list.append((score))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'Degree': degree, 'C': c}\n",
    "\n",
    "print(\"Best score: {:.4f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "\n",
    "lregSVRP = SVR(kernel='poly', degree=2, C=1000, gamma='auto')\n",
    "lregSVRP.fit(x_train_pca,y_train)\n",
    "cslregSVRP=cross_val_score(lregSVRP,x_train_pca,y_train,cv=5)\n",
    "Cross_validation_Score = Cross_validation_Score.append({'Model':'SVM Kernel=Poly','Mean_Score':cslregSVRP.mean(),'Std':cslregSVRP.std() * 2}, ignore_index=True)\n",
    "print(\"Avg Cross validation score: %0.6f (+/- %0.2f)\" % (cslregSVRP.mean(), cslregSVRP.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 KNeighborsRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6847\n",
      "Best parameters: {'K': 9}\n",
      "Avg Cross validation score: 0.606448 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "train_score_list = []\n",
    "test_score_list = []\n",
    "K=[1,2,3,4,5,6,7,8,9]\n",
    "best_score=0\n",
    "for k in range(1,10):\n",
    "    knn_reg = KNeighborsRegressor(k)\n",
    "    knn_reg.fit(x_tr_pca, y_tr)\n",
    "    train_score_list.append(knn_reg.score(x_tr_pca, y_tr))\n",
    "    score=knn_reg.score(x_val_pca, y_val)\n",
    "    test_score_list.append((score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameters = {'K': k}\n",
    "\n",
    "print(\"Best score: {:.4f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "\n",
    "knn_reg = KNeighborsRegressor(4)\n",
    "csknn_reg=cross_val_score(knn_reg,x_train_pca,y_train,cv=5)\n",
    "Cross_validation_Score = Cross_validation_Score.append({'Model':'KNeighborsRegressor','Mean_Score':csknn_reg.mean(),'Std':csknn_reg.std() * 2}, ignore_index=True)\n",
    "print(\"Avg Cross validation score: %0.6f (+/- %0.2f)\" % (csknn_reg.mean(), csknn_reg.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 .Performance Comparison : PCA and Non PCA DataSet\n",
    "### 6.1 Non PCA Resuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model  Mean_Score       Std\n",
      "0      Linear Regression    0.955076  0.013500\n",
      "1                  Ridge    0.954983  0.015913\n",
      "2       Lasso Regression    0.894714  0.023043\n",
      "3  Polynomial Regression    0.954351  0.012865\n",
      "4             SVM Simple    0.885082  0.068014\n",
      "5       SVM Kernel=Linea    0.915591  0.034254\n",
      "6         SVM Kernel=rbf    0.957147  0.016217\n",
      "7        SVM Kernel=Poly    0.822728  0.029408\n",
      "8    KNeighborsRegressor    0.888586  0.026405\n"
     ]
    }
   ],
   "source": [
    "cvsl={'Model':[],'Mean_Score':[],'Std':[]}\n",
    "Non_PCA_Score = pd.DataFrame(cvsl)\n",
    "Non_PCA_Score = Non_PCA_Score.append({'Model':'Linear Regression','Mean_Score':0.955076,'Std':0.013500}, ignore_index=True)\n",
    "Non_PCA_Score = Non_PCA_Score.append({'Model':'Ridge','Mean_Score':0.954983,'Std':0.015913}, ignore_index=True)\n",
    "Non_PCA_Score = Non_PCA_Score.append({'Model':'Lasso Regression','Mean_Score':0.894714,'Std':0.023043}, ignore_index=True)\n",
    "Non_PCA_Score = Non_PCA_Score.append({'Model':'Polynomial Regression','Mean_Score':0.954351,'Std':0.012865}, ignore_index=True)\n",
    "Non_PCA_Score = Non_PCA_Score.append({'Model':'SVM Simple','Mean_Score':0.885082,'Std':0.068014}, ignore_index=True)\n",
    "Non_PCA_Score = Non_PCA_Score.append({'Model':'SVM Kernel=Linea','Mean_Score':0.915591,'Std':0.034254}, ignore_index=True)\n",
    "Non_PCA_Score = Non_PCA_Score.append({'Model':'SVM Kernel=rbf','Mean_Score':0.957147,'Std':0.016217}, ignore_index=True)\n",
    "Non_PCA_Score = Non_PCA_Score.append({'Model':'SVM Kernel=Poly','Mean_Score':0.822728,'Std':0.029408}, ignore_index=True)\n",
    "Non_PCA_Score = Non_PCA_Score.append({'Model':'KNeighborsRegressor','Mean_Score':0.888586,'Std':0.026405}, ignore_index=True)\n",
    "print(pd.DataFrame(Non_PCA_Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 PCA Resuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model  Mean_Score       Std\n",
      "0      Linear Regression    0.854794  0.024134\n",
      "1                  Ridge    0.856707  0.023984\n",
      "2                  Lasso    0.842413  0.027182\n",
      "3  Polynomial Regression    0.854794  0.024134\n",
      "4             SVM Simple    0.836388  0.039319\n",
      "5      SVM Kernel=Linear    0.836355  0.038256\n",
      "6         SVM Kernel=rbf    0.936589  0.015297\n",
      "7        SVM Kernel=Poly    0.183494  0.089108\n",
      "8    KNeighborsRegressor    0.606448  0.062731\n"
     ]
    }
   ],
   "source": [
    "Cross_validation_Score = Cross_validation_Score.drop_duplicates()\n",
    "print(Cross_validation_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on above tables, Regression algorithm performs betters with non reduced(PCA) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deep Learning Model\n",
    "###  6.1 with optimizer = SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(10)\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=218, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='sgd' , metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2196/2196 [==============================] - 0s 74us/step - loss: 1462.5812 - mse: 1462.5815\n",
      "Epoch 2/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 72.6421 - mse: 72.6421\n",
      "Epoch 3/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 45.2953 - mse: 45.2953\n",
      "Epoch 4/100\n",
      "2196/2196 [==============================] - 0s 52us/step - loss: 24.0217 - mse: 24.0217\n",
      "Epoch 5/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 22.0546 - mse: 22.0546\n",
      "Epoch 6/100\n",
      "2196/2196 [==============================] - 0s 59us/step - loss: 17.5264 - mse: 17.5264\n",
      "Epoch 7/100\n",
      "2196/2196 [==============================] - 0s 52us/step - loss: 20.1456 - mse: 20.1456\n",
      "Epoch 8/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 22.9740 - mse: 22.9740\n",
      "Epoch 9/100\n",
      "2196/2196 [==============================] - 0s 69us/step - loss: 12.3155 - mse: 12.3155\n",
      "Epoch 10/100\n",
      "2196/2196 [==============================] - 0s 56us/step - loss: 14.5591 - mse: 14.5591\n",
      "Epoch 11/100\n",
      "2196/2196 [==============================] - 0s 57us/step - loss: 14.7794 - mse: 14.7794\n",
      "Epoch 12/100\n",
      "2196/2196 [==============================] - 0s 77us/step - loss: 13.0176 - mse: 13.0176\n",
      "Epoch 13/100\n",
      "2196/2196 [==============================] - 0s 74us/step - loss: 10.7388 - mse: 10.7388\n",
      "Epoch 14/100\n",
      "2196/2196 [==============================] - 0s 57us/step - loss: 13.8463 - mse: 13.8463\n",
      "Epoch 15/100\n",
      "2196/2196 [==============================] - 0s 59us/step - loss: 11.0687 - mse: 11.0687\n",
      "Epoch 16/100\n",
      "2196/2196 [==============================] - 0s 107us/step - loss: 11.5659 - mse: 11.5659\n",
      "Epoch 17/100\n",
      "2196/2196 [==============================] - 0s 89us/step - loss: 10.5509 - mse: 10.5509\n",
      "Epoch 18/100\n",
      "2196/2196 [==============================] - 0s 80us/step - loss: 10.9654 - mse: 10.9654\n",
      "Epoch 19/100\n",
      "2196/2196 [==============================] - 0s 110us/step - loss: 9.8537 - mse: 9.8537\n",
      "Epoch 20/100\n",
      "2196/2196 [==============================] - 0s 69us/step - loss: 9.9047 - mse: 9.9047\n",
      "Epoch 21/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 9.3688 - mse: 9.3688\n",
      "Epoch 22/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 9.8041 - mse: 9.8041\n",
      "Epoch 23/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 9.1617 - mse: 9.1617\n",
      "Epoch 24/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 7.3759 - mse: 7.3759\n",
      "Epoch 25/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 9.9994 - mse: 9.9994\n",
      "Epoch 26/100\n",
      "2196/2196 [==============================] - 0s 56us/step - loss: 8.6388 - mse: 8.6388\n",
      "Epoch 27/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 9.0222 - mse: 9.0222\n",
      "Epoch 28/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 8.3351 - mse: 8.3351\n",
      "Epoch 29/100\n",
      "2196/2196 [==============================] - 0s 70us/step - loss: 10.4468 - mse: 10.4468\n",
      "Epoch 30/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 9.8259 - mse: 9.8259\n",
      "Epoch 31/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 7.5117 - mse: 7.5117\n",
      "Epoch 32/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 10.8613 - mse: 10.8613\n",
      "Epoch 33/100\n",
      "2196/2196 [==============================] - 0s 86us/step - loss: 8.2803 - mse: 8.2803\n",
      "Epoch 34/100\n",
      "2196/2196 [==============================] - 0s 85us/step - loss: 7.1461 - mse: 7.1461\n",
      "Epoch 35/100\n",
      "2196/2196 [==============================] - 0s 120us/step - loss: 7.9138 - mse: 7.9138\n",
      "Epoch 36/100\n",
      "2196/2196 [==============================] - 0s 66us/step - loss: 7.2225 - mse: 7.2225\n",
      "Epoch 37/100\n",
      "2196/2196 [==============================] - 0s 59us/step - loss: 7.4588 - mse: 7.4588\n",
      "Epoch 38/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 6.6637 - mse: 6.6637\n",
      "Epoch 39/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 8.8906 - mse: 8.8906\n",
      "Epoch 40/100\n",
      "2196/2196 [==============================] - 0s 70us/step - loss: 7.2721 - mse: 7.2721\n",
      "Epoch 41/100\n",
      "2196/2196 [==============================] - 0s 89us/step - loss: 9.2797 - mse: 9.2797\n",
      "Epoch 42/100\n",
      "2196/2196 [==============================] - 0s 66us/step - loss: 6.3253 - mse: 6.3253\n",
      "Epoch 43/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 8.2088 - mse: 8.2088\n",
      "Epoch 44/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 7.5102 - mse: 7.5102\n",
      "Epoch 45/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 8.5365 - mse: 8.5365\n",
      "Epoch 46/100\n",
      "2196/2196 [==============================] - 0s 59us/step - loss: 8.1216 - mse: 8.1216\n",
      "Epoch 47/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 7.2694 - mse: 7.2694\n",
      "Epoch 48/100\n",
      "2196/2196 [==============================] - 0s 56us/step - loss: 6.3463 - mse: 6.3463\n",
      "Epoch 49/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 5.0119 - mse: 5.0119\n",
      "Epoch 50/100\n",
      "2196/2196 [==============================] - 0s 59us/step - loss: 7.6596 - mse: 7.6596\n",
      "Epoch 51/100\n",
      "2196/2196 [==============================] - 0s 93us/step - loss: 5.7199 - mse: 5.7199\n",
      "Epoch 52/100\n",
      "2196/2196 [==============================] - 0s 68us/step - loss: 7.1811 - mse: 7.1811\n",
      "Epoch 53/100\n",
      "2196/2196 [==============================] - 0s 61us/step - loss: 4.7676 - mse: 4.7676\n",
      "Epoch 54/100\n",
      "2196/2196 [==============================] - 0s 57us/step - loss: 5.7047 - mse: 5.7047\n",
      "Epoch 55/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 5.4992 - mse: 5.4992\n",
      "Epoch 56/100\n",
      "2196/2196 [==============================] - 0s 59us/step - loss: 4.7242 - mse: 4.7242\n",
      "Epoch 57/100\n",
      "2196/2196 [==============================] - 0s 61us/step - loss: 4.5476 - mse: 4.5476\n",
      "Epoch 58/100\n",
      "2196/2196 [==============================] - 0s 52us/step - loss: 7.1204 - mse: 7.1204\n",
      "Epoch 59/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 6.3618 - mse: 6.3618\n",
      "Epoch 60/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 5.1442 - mse: 5.1442\n",
      "Epoch 61/100\n",
      "2196/2196 [==============================] - 0s 52us/step - loss: 6.1780 - mse: 6.1780\n",
      "Epoch 62/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 5.7082 - mse: 5.7082\n",
      "Epoch 63/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 5.1652 - mse: 5.1652\n",
      "Epoch 64/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 4.4261 - mse: 4.4261\n",
      "Epoch 65/100\n",
      "2196/2196 [==============================] - 0s 61us/step - loss: 5.0797 - mse: 5.0797\n",
      "Epoch 66/100\n",
      "2196/2196 [==============================] - 0s 50us/step - loss: 4.4164 - mse: 4.4164\n",
      "Epoch 67/100\n",
      "2196/2196 [==============================] - 0s 52us/step - loss: 4.4972 - mse: 4.4972\n",
      "Epoch 68/100\n",
      "2196/2196 [==============================] - 0s 82us/step - loss: 4.6277 - mse: 4.6277\n",
      "Epoch 69/100\n",
      "2196/2196 [==============================] - 0s 81us/step - loss: 4.9062 - mse: 4.9062\n",
      "Epoch 70/100\n",
      "2196/2196 [==============================] - 0s 63us/step - loss: 4.1672 - mse: 4.1672\n",
      "Epoch 71/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 3.9219 - mse: 3.9219\n",
      "Epoch 72/100\n",
      "2196/2196 [==============================] - 0s 86us/step - loss: 3.6632 - mse: 3.6632\n",
      "Epoch 73/100\n",
      "2196/2196 [==============================] - 0s 77us/step - loss: 5.1893 - mse: 5.1893\n",
      "Epoch 74/100\n",
      "2196/2196 [==============================] - 0s 57us/step - loss: 4.3071 - mse: 4.3071\n",
      "Epoch 75/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 3.6113 - mse: 3.6113\n",
      "Epoch 76/100\n",
      "2196/2196 [==============================] - 0s 49us/step - loss: 4.7012 - mse: 4.7012\n",
      "Epoch 77/100\n",
      "2196/2196 [==============================] - 0s 88us/step - loss: 3.7235 - mse: 3.7235\n",
      "Epoch 78/100\n",
      "2196/2196 [==============================] - 0s 73us/step - loss: 4.3765 - mse: 4.3765\n",
      "Epoch 79/100\n",
      "2196/2196 [==============================] - 0s 57us/step - loss: 3.6578 - mse: 3.6578\n",
      "Epoch 80/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 4.1874 - mse: 4.1874\n",
      "Epoch 81/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 3.3538 - mse: 3.3538\n",
      "Epoch 82/100\n",
      "2196/2196 [==============================] - 0s 60us/step - loss: 4.0443 - mse: 4.0443\n",
      "Epoch 83/100\n",
      "2196/2196 [==============================] - 0s 57us/step - loss: 3.7842 - mse: 3.7842\n",
      "Epoch 84/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 3.6752 - mse: 3.6752\n",
      "Epoch 85/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 3.4536 - mse: 3.4536\n",
      "Epoch 86/100\n",
      "2196/2196 [==============================] - 0s 57us/step - loss: 3.3557 - mse: 3.3557\n",
      "Epoch 87/100\n",
      "2196/2196 [==============================] - 0s 58us/step - loss: 3.4896 - mse: 3.4896\n",
      "Epoch 88/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 3.4590 - mse: 3.4590\n",
      "Epoch 89/100\n",
      "2196/2196 [==============================] - 0s 50us/step - loss: 3.1935 - mse: 3.1935\n",
      "Epoch 90/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 3.2156 - mse: 3.2156\n",
      "Epoch 91/100\n",
      "2196/2196 [==============================] - 0s 56us/step - loss: 3.3613 - mse: 3.3613\n",
      "Epoch 92/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 3.7255 - mse: 3.7255\n",
      "Epoch 93/100\n",
      "2196/2196 [==============================] - 0s 53us/step - loss: 3.9345 - mse: 3.9345\n",
      "Epoch 94/100\n",
      "2196/2196 [==============================] - 0s 57us/step - loss: 3.3212 - mse: 3.3212\n",
      "Epoch 95/100\n",
      "2196/2196 [==============================] - 0s 62us/step - loss: 2.8867 - mse: 2.8867\n",
      "Epoch 96/100\n",
      "2196/2196 [==============================] - 0s 54us/step - loss: 3.5361 - mse: 3.5361\n",
      "Epoch 97/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 3.9071 - mse: 3.9071\n",
      "Epoch 98/100\n",
      "2196/2196 [==============================] - 0s 55us/step - loss: 3.9154 - mse: 3.9154\n",
      "Epoch 99/100\n",
      "2196/2196 [==============================] - 0s 52us/step - loss: 3.9818 - mse: 3.9818\n",
      "Epoch 100/100\n",
      "2196/2196 [==============================] - 0s 50us/step - loss: 3.3041 - mse: 3.3041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x262f9fbd708>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732/732 [==============================] - 0s 35us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.32135035692017, 4.321350574493408]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9737\n",
      "Test score: 0.9535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, recall_score, precision_score\n",
    "\n",
    "y_train_predict = model.predict(x_train)\n",
    "y_test_predict = model.predict(x_test)\n",
    "#print(pd.DataFrame(y_test_predict))\n",
    "print('Train score: {:.4f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test score: {:.4f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6.2 With optimizer = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "numpy.random.seed(10)\n",
    "\n",
    "def create_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=218, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    #compile model\n",
    "    model.compile(loss='mse', optimizer='Adam' , metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "model = KerasRegressor(build_fn = create_model, verbose = 0)\n",
    "param_grid = {'batch_size':[10,20] , 'epochs':[50,100]}\n",
    "grid_search = GridSearchCV(estimator= model, param_grid = param_grid, cv = 5)\n",
    "grid_search_result = grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 10, 'epochs': 100}\n",
      "Train score: 0.9811\n",
      "Test score: 0.9562\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "y_train_predict = grid_search.predict(x_train)\n",
    "y_test_predict = grid_search.predict(x_test)\n",
    "#print(pd.DataFrame(y_test_predict))\n",
    "print('Train score: {:.4f}'.format(r2_score(y_train, y_train_predict)))\n",
    "print('Test score: {:.4f}'.format(r2_score(y_test, y_test_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
